{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e27c325-13d1-43f9-8c53-272ad61956e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch_geometric as tg\n",
    "import itertools\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, GCNConv, GATv2Conv\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops, softmax, get_laplacian, to_dense_adj\n",
    "from my_gat import my_GATConv\n",
    "from my_mlp_gat import GATv3Layer\n",
    "sys.path.insert(0, os.path.abspath('../../'))\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "import torch.nn.functional as F # <-- Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2456dcc8-1e6e-469d-b93c-6ebf5bb16858",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2b6ef3-adfc-4745-aa8d-104807be5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_GCN(torch.nn.Module):\n",
    "    def __init__(self, d, out_d):\n",
    "        super(Model_GCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(d,out_d, bias=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = self.conv1(x, data.edge_index)\n",
    "        \n",
    "        return x.squeeze(-1)\n",
    "    \n",
    "class Model_linear(torch.nn.Module):\n",
    "    def __init__(self, d, out_d):\n",
    "        super(Model_linear, self).__init__()\n",
    "        \n",
    "        self.linear = torch.nn.Linear(d,out_d, bias=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f033e9-d840-4fcf-8820-8821d97d9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eigen2(nn.Module):\n",
    "    def __init__(self, k):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, edge_idx, n, sigma):\n",
    "        # lap_idx, lap_wt = get_laplacian(edge_idx, normalization=\"sym\")\n",
    "        edge_adj = to_dense_adj(edge_idx)\n",
    "        eigenvals, eigenvecs = torch.linalg.eig(edge_adj)\n",
    "        top_eig = eigenvecs.squeeze(0)[:, 1:self.k+1]\n",
    "        top_eig = torch.real(top_eig)\n",
    "        \n",
    "        new_edge_features = torch.Tensor(edge_idx.size(1), 1).to(edge_idx.device)\n",
    "        new_edge_idx = edge_idx.T\n",
    "        \n",
    "        for idx, pair in enumerate(new_edge_idx):\n",
    "            i, j = pair\n",
    "            x_i_prime = top_eig[i]\n",
    "            x_j_prime = top_eig[j]\n",
    "            dot = torch.dot(x_i_prime, x_j_prime)\n",
    "            final = 8 * torch.sqrt(torch.log(torch.tensor(n))) * sigma * torch.sign(dot)\n",
    "            new_edge_features[idx] = final\n",
    "            \n",
    "        return new_edge_features.view(-1, 1)\n",
    "\n",
    "class Model_GATv3(torch.nn.Module):\n",
    "    def __init__(self, d, out_d):\n",
    "        super(Model_GATv3, self).__init__()\n",
    "        \n",
    "        self.eigen = Eigen2(1)\n",
    "        self.conv1 = GATv3Layer(\n",
    "            in_channels=d, \n",
    "            out_channels=out_d,\n",
    "            att_in_channels=2,\n",
    "            att_out_channels=4,\n",
    "            share_weights=True, \n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, data, mu):\n",
    "        x = data.x\n",
    "        # e = data.edge_index\n",
    "        # y = data.y\n",
    "        n = x.size(0)\n",
    "\n",
    "        # p, q = get_graph_stats(e, y)\n",
    "        sigma = torch.std(x)\n",
    "\n",
    "        eigen_x = self.eigen(data.edge_index, n=n, sigma=0.1)\n",
    "        x, attn_weights, pair_pred = self.conv1(x, data.edge_index, edge_attr=eigen_x, cur_mu=mu, sigma=0.1, return_attention_info=True)\n",
    "        \n",
    "        return x.squeeze(-1), attn_weights, pair_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b2918e-6f57-49bd-b1de-f9c60a72bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def measure_accuracy(model, data):\n",
    "    model.eval()\n",
    "         \n",
    "    logits = model(data) # forward operation\n",
    "    preds = torch.sigmoid(logits) > 0.5\n",
    "    \n",
    "    # calculate training accuracy\n",
    "    correct = preds[data.train_mask] == data.ynew[data.train_mask]\n",
    "    train_acc = int(correct.sum()) / int(data.train_mask.sum())\n",
    "    \n",
    "    # calculate training accuracy\n",
    "    correct = preds[data.test_mask] == data.ynew[data.test_mask]\n",
    "    test_acc = int(correct.sum()) / int(data.test_mask.sum())\n",
    "        \n",
    "    return train_acc, test_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_accuracy_gat(model, data, mu):\n",
    "    model.eval()\n",
    "         \n",
    "    logits, attn_weights, pair_pred = model(data, mu) # forward operation\n",
    "    preds = torch.sigmoid(logits) > 0.5\n",
    "    \n",
    "    # calculate training accuracy\n",
    "    correct = preds[data.train_mask] == data.ynew[data.train_mask]\n",
    "    train_acc = int(correct.sum()) / int(data.train_mask.sum())\n",
    "    \n",
    "    # calculate training accuracy\n",
    "    correct = preds[data.test_mask] == data.ynew[data.test_mask]\n",
    "    test_acc = int(correct.sum()) / int(data.test_mask.sum())\n",
    "        \n",
    "    return train_acc, test_acc, attn_weights, pair_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7269c3c2-1f0d-4fc9-a523-481ceffc3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def info_mlp_gat(attn_weights, idx, head):\n",
    "    intra_weight = []\n",
    "    idx_intra = []\n",
    "    inter_weight = []\n",
    "    idx_inter = []\n",
    "\n",
    "    weights = attn_weights[1] # get gamma values\n",
    "\n",
    "    idx_class0 = idx.nonzero(as_tuple=True)[0]\n",
    "    idx_class1 = (~idx).nonzero(as_tuple=True)[0]\n",
    "    for i in range(attn_weights[0].shape[1]):\n",
    "        edge = [attn_weights[0][0][i].item(),attn_weights[0][1][i].item()]\n",
    "        if ((edge[0] in idx_class0) and (edge[1] in idx_class0)) or ((edge[0] in idx_class1) and (edge[1] in idx_class1)):\n",
    "            intra_weight.append(weights[i].item())\n",
    "            idx_intra.append(i)\n",
    "        else:\n",
    "            inter_weight.append(weights[i].item())\n",
    "            idx_inter.append(i)\n",
    "    return intra_weight, idx_intra, inter_weight, idx_inter\n",
    "\n",
    "def info_mlp_gat_scores_phi(attn_weights, idx, head):\n",
    "    idx_intra = []\n",
    "    idx_inter = []\n",
    "    \n",
    "    intra_weight_00 = []\n",
    "    intra_weight_11 = []\n",
    "    \n",
    "    inter_weight_01 = []\n",
    "    inter_weight_10 = []\n",
    "\n",
    "    weights = attn_weights[2] # get attention scores\n",
    "\n",
    "    idx_class0 = idx.nonzero(as_tuple=True)[0]\n",
    "    idx_class1 = (~idx).nonzero(as_tuple=True)[0]\n",
    "    for i in range(attn_weights[0].shape[1]):\n",
    "        edge = [attn_weights[0][0][i].item(),attn_weights[0][1][i].item()]\n",
    "        if ((edge[0] in idx_class0) and (edge[1] in idx_class0)):\n",
    "            intra_weight_00.append(weights[i].item())\n",
    "            idx_intra.append(i)\n",
    "        elif ((edge[0] in idx_class1) and (edge[1] in idx_class1)):\n",
    "            intra_weight_11.append(weights[i].item())\n",
    "            idx_intra.append(i)\n",
    "        elif ((edge[0] in idx_class0) and (edge[1] in idx_class1)):\n",
    "            inter_weight_01.append(weights[i].item())\n",
    "            idx_inter.append(i)\n",
    "        elif ((edge[0] in idx_class1) and (edge[1] in idx_class0)):\n",
    "            inter_weight_10.append(weights[i].item())\n",
    "            idx_inter.append(i)\n",
    "            \n",
    "    return intra_weight_00, intra_weight_11, idx_intra, inter_weight_01, inter_weight_10, idx_inter\n",
    "\n",
    "def info_mlp_gat_scores_psi(attn_weights, idx, head):\n",
    "    idx_intra = []\n",
    "    idx_inter = []\n",
    "    \n",
    "    intra_weight_00 = []\n",
    "    intra_weight_11 = []\n",
    "    \n",
    "    inter_weight_01 = []\n",
    "    inter_weight_10 = []\n",
    "\n",
    "    weights = attn_weights[3] # get attention scores\n",
    "\n",
    "    idx_class0 = idx.nonzero(as_tuple=True)[0]\n",
    "    idx_class1 = (~idx).nonzero(as_tuple=True)[0]\n",
    "    for i in range(attn_weights[0].shape[1]):\n",
    "        edge = [attn_weights[0][0][i].item(),attn_weights[0][1][i].item()]\n",
    "        if ((edge[0] in idx_class0) and (edge[1] in idx_class0)):\n",
    "            intra_weight_00.append(weights[i].item())\n",
    "            idx_intra.append(i)\n",
    "        elif ((edge[0] in idx_class1) and (edge[1] in idx_class1)):\n",
    "            intra_weight_11.append(weights[i].item())\n",
    "            idx_intra.append(i)\n",
    "        elif ((edge[0] in idx_class0) and (edge[1] in idx_class1)):\n",
    "            inter_weight_01.append(weights[i].item())\n",
    "            idx_inter.append(i)\n",
    "        elif ((edge[0] in idx_class1) and (edge[1] in idx_class0)):\n",
    "            inter_weight_10.append(weights[i].item())\n",
    "            idx_inter.append(i)\n",
    "            \n",
    "    return intra_weight_00, intra_weight_11, idx_intra, inter_weight_01, inter_weight_10, idx_inter\n",
    "\n",
    "def pair_acc(n_edges, pair_pred, idx_intra, idx_inter, head):\n",
    "    \n",
    "    tmp = torch.zeros(n_edges).to(device)\n",
    "    tmp[pair_pred[:,head].reshape(len(pair_pred)) > 0] = 1\n",
    "\n",
    "    gt = torch.zeros(n_edges).to(device)\n",
    "    gt[idx_intra] = 1\n",
    "\n",
    "    acc_intra_edges = 1 - torch.sum(torch.abs(gt[idx_intra] - tmp[idx_intra]))/len(idx_intra)\n",
    "    acc_inter_edges = 1 - torch.sum(torch.abs(gt[idx_inter] - tmp[idx_inter]))/len(idx_inter)\n",
    "    print(\"Head: \", head, \" acc intra edges: \", acc_intra_edges.item(), \" acc inter edges: \", acc_inter_edges.item())\n",
    "    \n",
    "    return acc_intra_edges, acc_inter_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7924ac01-5e8a-4859-8156-6839b42ecd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_plot(name, which_class, heads, mus, degree, intra_gamma, inter_gamma, intra_gamma_, inter_gamma_, \n",
    "            intra_gamma_std, inter_gamma_std, intra_gamma_std_, inter_gamma_std_, \n",
    "            test_acc_mlp_gat, test_acc_gat, test_acc_gcn, test_acc_lin, \n",
    "            acc_intra_edges_all, acc_inter_edges_all, acc_intra_edges_all_, acc_inter_edges_all_,\n",
    "            phi_intra_attn_00, phi_intra_attn_11, phi_inter_attn_01, phi_inter_attn_10,\n",
    "            phi_intra_attn_00_std, phi_intra_attn_11_std, phi_inter_attn_01_std, phi_inter_attn_10_std,\n",
    "            psi_intra_attn_00, psi_intra_attn_11, psi_inter_attn_01, psi_inter_attn_10,\n",
    "            psi_intra_attn_00_std, psi_intra_attn_11_std, psi_inter_attn_01_std, psi_inter_attn_10_std):\n",
    "    \n",
    "    mus = mus.cpu()\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 7), dpi=80)\n",
    "\n",
    "    plt.plot(mus,intra_gamma, linewidth=2, linestyle='-', marker='*', markersize=9, label='Average $\\gamma$, intra edges, MLP-GAT')\n",
    "#     plt.fill_between(mus,np.asarray(intra_gamma)-np.asarray(intra_gamma_std),np.asarray(intra_gamma)+np.asarray(intra_gamma_std),alpha=0.4)\n",
    "\n",
    "    plt.plot(mus,inter_gamma, linewidth=2, linestyle='-', marker='X', markersize=9, label='Average $\\gamma$, inter edges, MLP-GAT')\n",
    "#     plt.fill_between(mus,np.asarray(inter_gamma)-np.asarray(inter_gamma_std),np.asarray(inter_gamma)+np.asarray(inter_gamma_std),alpha=0.4)\n",
    "    \n",
    "    d_mean = (1+degree).mean().cpu()\n",
    "#     inv_d_std = (1/(1+degree)).std().cpu()\n",
    "    inv_degree_mean_vec = (1/d_mean)*np.ones(len(mus))\n",
    "    \n",
    "    plt.plot(mus,inv_degree_mean_vec, linewidth=2, linestyle='-', marker='o', markersize=9, color = 'black', label='Average $1/|N_i|$')\n",
    "#     plt.fill_between(mus,inv_degree_mean_vec-inv_d_std,inv_degree_mean_vec+inv_d_std,alpha=0.4)\n",
    "\n",
    "    plt.grid(linestyle='dashed')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xscale('log')\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    plt.xlabel('Distance between means', fontsize=20)\n",
    "    plt.ylabel('$\\gamma$ value', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(\"sanity/gammas_MLPGAT_real_data_ansatz_\"+name+\"_class_\"+str(which_class)+\"_indicator.pdf\", dpi=400, bbox_inches='tight')\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 7), dpi=80)\n",
    "\n",
    "    plt.plot(mus,intra_gamma_std, linewidth=2, linestyle='-', marker='*', markersize=9, label='Stand. dev. $\\gamma$, intra edges, MLP-GAT')\n",
    "\n",
    "    plt.plot(mus,inter_gamma_std, linewidth=2, linestyle='-', marker='X', markersize=9, label='Stand. dev. $\\gamma$, inter edges, MLP-GAT')\n",
    "    \n",
    "#     d_mean = (1+degree).mean().cpu()\n",
    "    inv_d_std = (1/(1+degree)).std().cpu()\n",
    "#     inv_degree_mean_vec = (1/d_mean)*np.ones(len(mus))\n",
    "    \n",
    "    plt.plot(mus,inv_d_std*np.ones(len(mus)), linewidth=2, linestyle='-', marker='o', markersize=9, color = 'black', label='Stand. dev. of $1/|N_i|$')\n",
    "\n",
    "    plt.grid(linestyle='dashed')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xscale('log')\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    plt.xlabel('Distance between means', fontsize=20)\n",
    "    plt.ylabel('Value', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(\"sanity/gammas_std_MLPGAT_real_data_ansatz_\"+name+\"_class_\"+str(which_class)+\"_indicator.pdf\", dpi=400, bbox_inches='tight')\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 12), dpi=80)\n",
    "\n",
    "    marker_intra = ['v','^','>','<']\n",
    "    marker_inter = ['1','2','3','4']\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 7), dpi=80)\n",
    "\n",
    "    plt.plot(mus,test_acc_mlp_gat, linewidth=2, linestyle='-', marker='*', markersize=9, label='MLP-GAT')\n",
    "    plt.plot(mus,test_acc_gcn, linewidth=2, linestyle='-', marker='s', markersize=9, label='GCN')\n",
    "    plt.plot(mus,test_acc_lin, linewidth=2, linestyle='-', marker='D', markersize=9, color = 'purple', label='No-graph')\n",
    "\n",
    "    plt.grid(linestyle='dashed')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xscale('log')\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    plt.xlabel('Distance between means', fontsize=20)\n",
    "    plt.ylabel('Classification accuracy', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(\"sanity/node_classification_MLPGAT_real_data_ansatz_\"+name+\"_class_\"+str(which_class)+\"_indicator.pdf\", dpi=400, bbox_inches='tight')\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 7), dpi=80)\n",
    "\n",
    "    plt.plot(mus,acc_intra_edges_all, linewidth=2, linestyle='-', marker='*', markersize=9, label='MLP-GAT, intra edge classification')\n",
    "    plt.plot(mus,acc_inter_edges_all, linewidth=2, linestyle='-', marker='X', markersize=9, label='MLP-GAT, inter edge classification')\n",
    "    \n",
    "#     for head in range(heads):\n",
    "#         plt.plot(mus,acc_intra_edges_all_[head], linewidth=2, linestyle='-', marker=marker_intra[head], markersize=9, label='GAT, intra edge classification'+' head '+str(head))\n",
    "#         plt.plot(mus,acc_inter_edges_all_[head], linewidth=2, linestyle='-', marker=marker_inter[head], markersize=9, label='GAT, inter edge classification'+' head '+str(head))       \n",
    "\n",
    "    plt.grid(linestyle='dashed')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xscale('log')\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    plt.xlabel('Distance between means', fontsize=20)\n",
    "    plt.ylabel('Classification accuracy', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(\"sanity/edge_classification_MLPGAT_real_data_ansatz_\"+name+\"_class_\"+str(which_class)+\"_indicator.pdf\", dpi=400, bbox_inches='tight')\n",
    "    \n",
    "    # ---------------------------------------PSI---------------------------------------\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 7), dpi=80)\n",
    "    \n",
    "    plt.plot(mus, psi_intra_attn_00, label=\"$i \\in C_0, j \\in C_0$\", linewidth=2, linestyle=\"-\", markersize=9, marker=\"*\")\n",
    "    plt.fill_between(mus, np.asarray(psi_intra_attn_00)-np.asarray(psi_intra_attn_00_std), np.asarray(psi_intra_attn_00)+np.asarray(psi_intra_attn_00_std), alpha=0.4)\n",
    "    \n",
    "    plt.plot(mus, psi_intra_attn_11, label=\"$i \\in C_1, j \\in C_1$\", linewidth=2, linestyle=\"-\", markersize=9, marker=\"X\")\n",
    "    plt.fill_between(mus, np.asarray(psi_intra_attn_11)-np.asarray(psi_intra_attn_11_std), np.asarray(psi_intra_attn_11)+np.asarray(psi_intra_attn_11_std), alpha=0.4)\n",
    "    \n",
    "    plt.plot(mus, psi_inter_attn_10, label=\"$i \\in C_1, j \\in C_0$\", linewidth=2, linestyle=\"-\", markersize=9, marker=\"+\")\n",
    "    plt.fill_between(mus, np.asarray(psi_inter_attn_10)-np.asarray(psi_inter_attn_10_std), np.asarray(psi_inter_attn_10)+np.asarray(psi_inter_attn_10_std), alpha=0.4)\n",
    "    \n",
    "    plt.plot(mus, psi_inter_attn_01, label=\"$i \\in C_0, j \\in C_1$\", linewidth=2, linestyle=\"-\", markersize=9, marker=\"o\")\n",
    "    plt.fill_between(mus, np.asarray(psi_inter_attn_01)-np.asarray(psi_inter_attn_01_std), np.asarray(psi_inter_attn_01)+np.asarray(psi_inter_attn_01_std), alpha=0.4)\n",
    "    \n",
    "    plt.grid(linestyle=\"dashed\")\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xscale('log')\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    plt.xlabel('Distance between means', fontsize=20)\n",
    "    plt.ylabel('$\\Psi$ Values', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(\"sanity/psi_values_MLPGAT_real_data_ansatz_\"+name+\"_class_\"+str(which_class)+\"_indicator.pdf\", dpi=400, bbox_inches='tight')\n",
    "    \n",
    "    # ---------------------------------------PHI---------------------------------------\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 7), dpi=80)\n",
    "    \n",
    "    plt.plot(mus, phi_intra_attn_00, label=\"$i \\in C_0, j \\in C_0$\", linewidth=2, linestyle=\"-\", markersize=9, marker=\"*\")\n",
    "    plt.fill_between(mus, np.asarray(phi_intra_attn_00)-np.asarray(phi_intra_attn_00_std), np.asarray(phi_intra_attn_00)+np.asarray(phi_intra_attn_00_std), alpha=0.4)\n",
    "    \n",
    "    plt.plot(mus, phi_intra_attn_11, label=\"$i \\in C_1, j \\in C_1$\", linewidth=2, linestyle=\"-\", markersize=9, marker=\"X\")\n",
    "    plt.fill_between(mus, np.asarray(phi_intra_attn_11)-np.asarray(phi_intra_attn_11_std), np.asarray(phi_intra_attn_11)+np.asarray(phi_intra_attn_11_std), alpha=0.4)\n",
    "    \n",
    "    plt.plot(mus, phi_inter_attn_10, label=\"$i \\in C_1, j \\in C_0$\", linewidth=2, linestyle=\"-\", markersize=9, marker=\"+\")\n",
    "    plt.fill_between(mus, np.asarray(phi_inter_attn_10)-np.asarray(phi_inter_attn_10_std), np.asarray(phi_inter_attn_10)+np.asarray(phi_inter_attn_10_std), alpha=0.4)\n",
    "    \n",
    "    plt.plot(mus, phi_inter_attn_01, label=\"$i \\in C_0, j \\in C_1$\", linewidth=2, linestyle=\"-\", markersize=9, marker=\"o\")\n",
    "    plt.fill_between(mus, np.asarray(phi_inter_attn_01)-np.asarray(phi_inter_attn_01_std), np.asarray(phi_inter_attn_01)+np.asarray(phi_inter_attn_01_std), alpha=0.4)\n",
    "    \n",
    "    plt.grid(linestyle=\"dashed\")\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xscale('log')\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    plt.xlabel('Distance between means', fontsize=20)\n",
    "    plt.ylabel('$\\Phi$ Values', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(\"sanity/phi_values_MLPGAT_real_data_ansatz_\"+name+\"_class_\"+str(which_class)+\"_indicator.pdf\", dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745447fe-b1b2-4f8c-93bb-267f6703480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ansatz_mlp_gat(model, mean, R):\n",
    "    \n",
    "    model_mlp_gat_ansatz = copy.deepcopy(model)\n",
    "    w = (R/torch.norm(mean))*mean\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_mlp_gat_ansatz.conv1.lin.weight = torch.nn.Parameter(w.reshape(1,w.shape[0]))\n",
    "        model_mlp_gat_ansatz.conv1.att_in.weight = torch.nn.Parameter(torch.tensor([[1.0,1.0],[-1.0,-1.0],[1.0,-1.0],[-1.0,1.0]])) # S\n",
    "        model_mlp_gat_ansatz.conv1.att_out.weight = torch.nn.Parameter(torch.tensor([[1.0, 1.0, -1.0, -1.0]])) # r\n",
    "\n",
    "    model_mlp_gat_ansatz.to(device)\n",
    "\n",
    "    return model_mlp_gat_ansatz\n",
    "\n",
    "def create_ansatz_gcn(model, mean, R):\n",
    "    \n",
    "    model_gcn_ansatz = copy.deepcopy(model)\n",
    "    w = (R/torch.norm(mean))*mean\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_gcn_ansatz.conv1.lin.weight = torch.nn.Parameter(w.reshape(1,w.shape[0]))\n",
    "\n",
    "    model_gcn_ansatz.to(device)\n",
    "\n",
    "    return model_gcn_ansatz\n",
    "\n",
    "def create_ansatz_linear(model, mean, R):\n",
    "    \n",
    "    model_linear_ansatz = copy.deepcopy(model)\n",
    "    w = (R/torch.norm(mean))*mean\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_linear_ansatz.linear.weight = torch.nn.Parameter(w.reshape(1,w.shape[0]))\n",
    "\n",
    "    model_linear_ansatz.to(device)\n",
    "\n",
    "    return model_linear_ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86073d21-bd34-4bca-8c1e-e76f7316a043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CiteSeer\n",
      "torch.Size([590]) torch.Size([596]) torch.Size([1186])\n",
      "torch.Size([590, 3703]) torch.Size([596, 3703]) torch.Size([1186, 3703])\n",
      "torch.Size([2, 2440])\n",
      "nclasses tensor(2)\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='data/CiteSeer/', name='CiteSeer')\n",
    "\n",
    "print(dataset.name)\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "c0 = 1\n",
    "c1 = 4\n",
    "\n",
    "y0 = data.y[data.y == c0]\n",
    "y1 = data.y[data.y == c1]\n",
    "y_final = torch.cat([y0, y1])\n",
    "y_final[y_final == c0] = 0\n",
    "y_final[y_final == c1] = 1\n",
    "n_nodes = y0.size(0) + y1.size(0)\n",
    "print (y0.shape, y1.shape, y_final.shape)\n",
    "\n",
    "new_train_mask_c0 = data.train_mask[data.y == c0]\n",
    "new_train_mask_c1 = data.train_mask[data.y == c1]\n",
    "new_train_mask = torch.cat([new_train_mask_c0, new_train_mask_c1])\n",
    "\n",
    "new_test_mask_c0 = data.test_mask[data.y == c0]\n",
    "new_test_mask_c1 = data.test_mask[data.y == c1]\n",
    "new_test_mask = torch.cat([new_test_mask_c0, new_test_mask_c1])\n",
    "\n",
    "x0 = data.x[data.y == c0]\n",
    "x1 = data.x[data.y == c1]\n",
    "x_final = torch.cat([x0, x1])\n",
    "print (x0.shape, x1.shape, x_final.shape)\n",
    "\n",
    "adj = tg.utils.to_dense_adj(data.edge_index).squeeze(0)\n",
    "target_idx = []\n",
    "for i in range(adj.size(0)):\n",
    "    if data.y[i] == c0 or data.y[i] == c1:\n",
    "        target_idx.append(i)\n",
    "        \n",
    "target_adj_rows = adj[target_idx, :]\n",
    "target_adj_rows = target_adj_rows[:, target_idx]\n",
    "new_edge_idx, _ = tg.utils.dense_to_sparse(target_adj_rows)\n",
    "print (new_edge_idx.shape)\n",
    "\n",
    "data.x = x_final\n",
    "data.y = y_final\n",
    "data.edge_index = new_edge_idx\n",
    "data.train_mask = new_train_mask\n",
    "data.test_mask = new_test_mask\n",
    "data.x_backup = copy.deepcopy(data.x)\n",
    "n = data.x.size(0)\n",
    "degree = tg.utils.degree(data.edge_index[1], n)\n",
    "n_classes = data.y.max() + 1\n",
    "print (\"nclasses\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37af745-cf19-4eb5-959c-36c96b47f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# edges:  2440\n",
      "p 1222 q 1218\n"
     ]
    }
   ],
   "source": [
    "def get_graph_stats(edge_idx, y):\n",
    "    new_edge_idx = edge_idx.T\n",
    "    total_edges = new_edge_idx.size(0)\n",
    "    p = 0\n",
    "    q = 0\n",
    "    for idx, pair in enumerate(new_edge_idx):\n",
    "        i, j = pair\n",
    "        if y[i] == y[j]:\n",
    "            p += 1\n",
    "        else:\n",
    "            q += 1\n",
    "    \n",
    "    # p = p/total_edges\n",
    "    # q = q/total_edges\n",
    "        \n",
    "    return p, q\n",
    "\n",
    "print (\"# edges: \", data.edge_index.size(1))\n",
    "p, q = get_graph_stats(data.edge_index, data.y)\n",
    "print (\"p\", p, \"q\", q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57e12a25-7fd6-491c-aa70-0b05c8104259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.9680317640304565: 1866, 0.0: 538, -1.9680317640304565: 36})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "eigen = Eigen2(1)\n",
    "eigen_x = eigen(data.edge_index, data.x.size(0), data.x.std())\n",
    "from collections import Counter\n",
    "ctr = Counter(eigen_x.view(-1).tolist())\n",
    "pprint (ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26618635-75b3-4f23-9026-0ef361a4e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  0\n",
      "mu/max(mus) tensor(0.0010, dtype=torch.float64)\n",
      "GCN\t\tTrain: 0.5000 | Test: 0.4815\n",
      "Linear\t\tTrain: 0.6000 | Test: 0.4986\n",
      "with indicator tensor(0.0001, dtype=torch.float64) 0.1\n",
      "MLP GAT ansatz\t\tTrain: 0.4250 | Test: 0.4558\n",
      "Head:  0  acc intra edges:  0.7545008063316345  acc inter edges:  0.22495895624160767\n",
      "MEAN_00 1.6830829150860127 650\n",
      "MEAN_11 1.4363061664821384 572\n",
      "MEAN_10 1.6251423558578115 609\n",
      "MEAN_01 1.6251423558578115 609\n",
      "mu/max(mus) tensor(0.0013, dtype=torch.float64)\n",
      "GCN\t\tTrain: 0.5000 | Test: 0.4900\n",
      "Linear\t\tTrain: 0.6000 | Test: 0.4986\n",
      "with indicator tensor(0.0001, dtype=torch.float64) 0.1\n",
      "MLP GAT ansatz\t\tTrain: 0.4250 | Test: 0.4530\n",
      "Head:  0  acc intra edges:  0.7545008063316345  acc inter edges:  0.22495895624160767\n",
      "MEAN_00 1.6830829150860127 650\n",
      "MEAN_11 1.4363061664821384 572\n",
      "MEAN_10 1.6251423558578115 609\n",
      "MEAN_01 1.6251423558578115 609\n",
      "mu/max(mus) tensor(0.0016, dtype=torch.float64)\n",
      "GCN\t\tTrain: 0.5000 | Test: 0.4957\n",
      "Linear\t\tTrain: 0.6000 | Test: 0.4986\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m test_acc_lin\u001b[38;5;241m.\u001b[39mappend(test_acc)\n\u001b[1;32m     85\u001b[0m model_gatv3_ansatz \u001b[38;5;241m=\u001b[39m create_ansatz_mlp_gat(Model_GATv3(data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], out_d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), new_mean0, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m train_acc, test_acc, attn_weights, pair_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_accuracy_gat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_gatv3_ansatz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLP GAT ansatz\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m test_acc_mlp_gat\u001b[38;5;241m.\u001b[39mappend(test_acc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyG2/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mmeasure_accuracy_gat\u001b[0;34m(model, data, mu)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure_accuracy_gat\u001b[39m(model, data, mu):\n\u001b[1;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 22\u001b[0m     logits, attn_weights, pair_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# forward operation\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(logits) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# calculate training accuracy\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyG2/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mModel_GATv3.forward\u001b[0;34m(self, data, mu)\u001b[0m\n\u001b[1;32m     44\u001b[0m n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# p, q = get_graph_stats(e, y)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m eigen_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigen(data\u001b[38;5;241m.\u001b[39medge_index, n\u001b[38;5;241m=\u001b[39mn, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     50\u001b[0m x, attn_weights, pair_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, data\u001b[38;5;241m.\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39meigen_x, cur_mu\u001b[38;5;241m=\u001b[39mmu, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, return_attention_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for which_class in range(n_classes):\n",
    "    print(\"Class: \", which_class)\n",
    "    y = torch.zeros(data.x.size(0), dtype=torch.float64).to(device)\n",
    "    idx = data.y == which_class\n",
    "    y[idx] = 1\n",
    "    data.ynew = y\n",
    "\n",
    "    mean0 = data.x_backup[idx].mean(dim=0)\n",
    "    mean1 = data.x_backup[~idx].mean(dim=0)\n",
    "\n",
    "    distance = torch.norm(mean0-mean1)\n",
    "    mu = distance/(2*torch.sqrt(torch.tensor(data.x.shape[1])))\n",
    "\n",
    "    mu_up = 10*mu\n",
    "    mu_lb = 0.01*mu\n",
    "\n",
    "    mus = torch.tensor(np.geomspace(mu_lb.item(), mu_up.item(), 30, endpoint=True)).to(device)\n",
    "\n",
    "    test_acc_mlp_gat = []\n",
    "    test_acc_gat = []\n",
    "    test_acc_gcn = []\n",
    "    test_acc_lin = []\n",
    "    intra_gamma = []\n",
    "    inter_gamma = []\n",
    "    intra_gamma_std = []\n",
    "    inter_gamma_std = []\n",
    "    acc_intra_edges_all = []\n",
    "    acc_inter_edges_all = []\n",
    "    intra_gamma_ = []\n",
    "    inter_gamma_ = []\n",
    "    intra_gamma_std_ = []\n",
    "    inter_gamma_std_ = []\n",
    "    acc_intra_edges_all_ = []\n",
    "    acc_inter_edges_all_ = []\n",
    "\n",
    "    phi_intra_attn_00 = []\n",
    "    phi_intra_attn_11 = []        \n",
    "    phi_inter_attn_01 = []\n",
    "    phi_inter_attn_10 = []\n",
    "\n",
    "    phi_intra_attn_00_std = []\n",
    "    phi_intra_attn_11_std = []        \n",
    "    phi_inter_attn_01_std = []\n",
    "    phi_inter_attn_10_std = []\n",
    "\n",
    "    psi_intra_attn_00 = []\n",
    "    psi_intra_attn_11 = []        \n",
    "    psi_inter_attn_01 = []\n",
    "    psi_inter_attn_10 = []\n",
    "\n",
    "    psi_intra_attn_00_std = []\n",
    "    psi_intra_attn_11_std = []        \n",
    "    psi_inter_attn_01_std = []\n",
    "    psi_inter_attn_10_std = []\n",
    "\n",
    "    heads = 2\n",
    "    for head in range(heads):\n",
    "        intra_gamma_.append([[],[]])\n",
    "        inter_gamma_.append([[],[]])\n",
    "        intra_gamma_std_.append([[],[]])\n",
    "        inter_gamma_std_.append([[],[]])\n",
    "        acc_intra_edges_all_.append([])\n",
    "        acc_inter_edges_all_.append([])\n",
    "\n",
    "    for mu_ in mus:\n",
    "\n",
    "        print(\"mu/max(mus)\", mu_/max(mus))\n",
    "\n",
    "        new_mean0 = mu_*torch.ones(data.x.shape[1]).to(device)\n",
    "        new_mean1 = -mu_*torch.ones(data.x.shape[1]).to(device)\n",
    "\n",
    "        data.x[idx] = data.x_backup[idx] - mean0 + new_mean0\n",
    "        data.x[~idx] = data.x_backup[~idx] - mean1 + new_mean1\n",
    "\n",
    "        model_gcn_ansatz = create_ansatz_gcn(Model_GCN(data.x.shape[1], out_d=1).to(device), new_mean0, 1)\n",
    "        train_acc, test_acc = measure_accuracy(model_gcn_ansatz, data)\n",
    "        print(f\"GCN\\t\\tTrain: {train_acc:0.4f} | Test: {test_acc:0.4f}\")\n",
    "        test_acc_gcn.append(test_acc)\n",
    "\n",
    "        model_linear_ansatz = create_ansatz_linear(Model_linear(data.x.shape[1], out_d=1).to(device), new_mean0, 1)\n",
    "        train_acc, test_acc = measure_accuracy(model_linear_ansatz, data)\n",
    "        print(f\"Linear\\t\\tTrain: {train_acc:0.4f} | Test: {test_acc:0.4f}\")\n",
    "        test_acc_lin.append(test_acc)\n",
    "\n",
    "        model_gatv3_ansatz = create_ansatz_mlp_gat(Model_GATv3(data.x.shape[1], out_d=1).to(device), new_mean0, 1)\n",
    "        train_acc, test_acc, attn_weights, pair_pred = measure_accuracy_gat(model_gatv3_ansatz, data, mu_)\n",
    "        print(f\"MLP GAT ansatz\\t\\tTrain: {train_acc:0.4f} | Test: {test_acc:0.4f}\")\n",
    "        test_acc_mlp_gat.append(test_acc)\n",
    "\n",
    "        intra_weight, idx_intra, inter_weight, idx_inter = info_mlp_gat(attn_weights, idx, 0)\n",
    "\n",
    "        intra_gamma.append(np.asarray(intra_weight).mean())\n",
    "        inter_gamma.append(np.asarray(inter_weight).mean())\n",
    "        intra_gamma_std.append(np.asarray(intra_weight).std())\n",
    "        inter_gamma_std.append(np.asarray(inter_weight).std())\n",
    "        acc_intra_edges, acc_inter_edges = pair_acc(attn_weights[0][0].shape[0], pair_pred, idx_intra, idx_inter, 0)\n",
    "        acc_intra_edges_all.append(acc_intra_edges.cpu())\n",
    "        acc_inter_edges_all.append(acc_inter_edges.cpu())\n",
    "\n",
    "        phi_intra_weight_00, phi_intra_weight_11, phi_idx_intra_scores, phi_inter_weight_01, phi_inter_weight_10, phi_idx_inter_scores = info_mlp_gat_scores_phi(attn_weights, idx, 0) # analyse phi scores\n",
    "        psi_intra_weight_00, psi_intra_weight_11, psi_idx_intra_scores, psi_inter_weight_01, psi_inter_weight_10, psi_idx_inter_scores = info_mlp_gat_scores_psi(attn_weights, idx, 0) # analyse psi scores\n",
    "        \n",
    "        print (\"MEAN_00\", np.asarray(psi_intra_weight_00).mean(), len(psi_intra_weight_00))\n",
    "        print (\"MEAN_11\", np.asarray(psi_intra_weight_11).mean(), len(psi_intra_weight_11))\n",
    "        print (\"MEAN_10\", np.asarray(psi_inter_weight_10).mean(), len(psi_inter_weight_10))\n",
    "        print (\"MEAN_01\", np.asarray(psi_inter_weight_01).mean(), len(psi_inter_weight_01))\n",
    "        \n",
    "        everything.append(\n",
    "            [\n",
    "                np.asarray(psi_intra_weight_00).mean(),\n",
    "                np.asarray(psi_intra_weight_11).mean()\n",
    "                np.asarray(psi_inter_weight_10).mean()\n",
    "                np.asarray(psi_inter_weight_01).mean()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        phi_intra_attn_00.append(np.asarray(phi_intra_weight_00).mean())\n",
    "        phi_intra_attn_11.append(np.asarray(phi_intra_weight_11).mean())\n",
    "        phi_inter_attn_01.append(np.asarray(phi_inter_weight_01).mean())\n",
    "        phi_inter_attn_10.append(np.asarray(phi_inter_weight_10).mean())\n",
    "\n",
    "        phi_intra_attn_00_std.append(np.asarray(phi_intra_weight_00).std())\n",
    "        phi_intra_attn_11_std.append(np.asarray(phi_intra_weight_11).std())\n",
    "        phi_inter_attn_01_std.append(np.asarray(phi_inter_weight_01).std())\n",
    "        phi_inter_attn_10_std.append(np.asarray(phi_inter_weight_10).std())\n",
    "\n",
    "        psi_intra_attn_00.append(np.asarray(psi_intra_weight_00).mean())\n",
    "        psi_intra_attn_11.append(np.asarray(psi_intra_weight_11).mean())\n",
    "        psi_inter_attn_01.append(np.asarray(psi_inter_weight_01).mean())\n",
    "        psi_inter_attn_10.append(np.asarray(psi_inter_weight_10).mean())\n",
    "\n",
    "        psi_intra_attn_00_std.append(np.asarray(psi_intra_weight_00).std())\n",
    "        psi_intra_attn_11_std.append(np.asarray(psi_intra_weight_11).std())\n",
    "        psi_inter_attn_01_std.append(np.asarray(psi_inter_weight_01).std())\n",
    "        psi_inter_attn_10_std.append(np.asarray(psi_inter_weight_10).std())\n",
    "\n",
    "    my_plot(\"Cora\", which_class, heads, mus, degree, intra_gamma, inter_gamma, intra_gamma_, inter_gamma_, \n",
    "            intra_gamma_std, inter_gamma_std, intra_gamma_std_, inter_gamma_std_, \n",
    "            test_acc_mlp_gat, test_acc_gat, test_acc_gcn, test_acc_lin, \n",
    "            acc_intra_edges_all, acc_inter_edges_all, acc_intra_edges_all_, acc_inter_edges_all_,\n",
    "            phi_intra_attn_00, phi_intra_attn_11, phi_inter_attn_01, phi_inter_attn_10,\n",
    "            phi_intra_attn_00_std, phi_intra_attn_11_std, phi_inter_attn_01_std, phi_inter_attn_10_std,\n",
    "            psi_intra_attn_00, psi_intra_attn_11, psi_inter_attn_01, psi_inter_attn_10,\n",
    "            psi_intra_attn_00_std, psi_intra_attn_11_std, psi_inter_attn_01_std, psi_inter_attn_10_std)\n",
    "    \n",
    "    print (everything)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c42bc-f5f6-4175-b459-2d2503516299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97173ef7-1959-4d8b-bffb-a31e5a7de39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
